{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6376c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "import logging\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee063d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa53f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading dataset...\n",
      "INFO:__main__:Preprocessing data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Obama says it is possible Russia would try to ...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. President Barack O...</td>\n",
       "      <td>0</td>\n",
       "      <td>Title: Obama says it is possible Russia would ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>U.S. challenged by rising North Korea tensions...</td>\n",
       "      <td>UNITED NATIONS (Reuters) - Russia urged “hot h...</td>\n",
       "      <td>0</td>\n",
       "      <td>Title: U.S. challenged by rising North Korea t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>THE WOMAN WHO Moved Freedom Loving Americans T...</td>\n",
       "      <td>MARCH 1st is the day! VOTE FOR BECKY GERRITSON...</td>\n",
       "      <td>1</td>\n",
       "      <td>Title: THE WOMAN WHO Moved Freedom Loving Amer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kenya president lifts travel restrictions, say...</td>\n",
       "      <td>NAIROBI (Reuters) - Kenyan President Uhuru Ken...</td>\n",
       "      <td>0</td>\n",
       "      <td>Title: Kenya president lifts travel restrictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Philippine ferry capsizes with 251 on board, f...</td>\n",
       "      <td>MANILA (Reuters) - Four people were killed and...</td>\n",
       "      <td>0</td>\n",
       "      <td>Title: Philippine ferry capsizes with 251 on b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                                              title  \\\n",
       "0          0  Obama says it is possible Russia would try to ...   \n",
       "1          1  U.S. challenged by rising North Korea tensions...   \n",
       "2          2  THE WOMAN WHO Moved Freedom Loving Americans T...   \n",
       "3          3  Kenya president lifts travel restrictions, say...   \n",
       "4          4  Philippine ferry capsizes with 251 on board, f...   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  WASHINGTON (Reuters) - U.S. President Barack O...      0   \n",
       "1  UNITED NATIONS (Reuters) - Russia urged “hot h...      0   \n",
       "2  MARCH 1st is the day! VOTE FOR BECKY GERRITSON...      1   \n",
       "3  NAIROBI (Reuters) - Kenyan President Uhuru Ken...      0   \n",
       "4  MANILA (Reuters) - Four people were killed and...      0   \n",
       "\n",
       "                                          input_text  \n",
       "0  Title: Obama says it is possible Russia would ...  \n",
       "1  Title: U.S. challenged by rising North Korea t...  \n",
       "2  Title: THE WOMAN WHO Moved Freedom Loving Amer...  \n",
       "3  Title: Kenya president lifts travel restrictio...  \n",
       "4  Title: Philippine ferry capsizes with 251 on b...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your dataset (assuming a CSV file with 'title', 'text', 'label' columns)\n",
    "logger.info(\"Loading dataset...\")\n",
    "df = pd.read_csv(\"final_data.csv\")\n",
    "\n",
    "df['label'] = df['label'].apply(lambda x: 1 if x == 'fake' else 0)\n",
    "df = df.dropna(subset='title')\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Preprocess the data by concatenating title and text\n",
    "logger.info(\"Preprocessing data...\")\n",
    "df['input_text'] = \"Title: \" + df['title'] + \" Text: \" + df['text']\n",
    "texts = df['input_text'].tolist()\n",
    "labels = df['label'].astype(int).tolist()\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40063f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the dataset with optimization for smaller batch size and sequence length\n",
    "logger.info(\"Tokenizing data...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokenized_inputs = tokenizer(texts, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be67caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Hugging Face Dataset format\n",
    "input_ids = tokenized_inputs[\"input_ids\"].tolist()\n",
    "attention_mask = tokenized_inputs[\"attention_mask\"].tolist()\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "dataset = Dataset.from_dict({\n",
    "    \"input_ids\": input_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"labels\": labels  # `labels` should already be in list format\n",
    "})\n",
    "\n",
    "# Split dataset for training and validation\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db580a63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading model...\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the DistilBERT model for sequence classification\n",
    "logger.info(\"Loading model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Define training arguments optimized for MacBook M1 Air\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,  # Smaller batch size to fit within M1 Air's memory limits\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    use_mps_device=True  # Use Apple M1's Metal API for acceleration\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9acdf01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing Trainer...\n",
      "INFO:__main__:Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33093' max='33093' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33093/33093 4:19:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.111600</td>\n",
       "      <td>0.152570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135100</td>\n",
       "      <td>0.163473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.228265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2758' max='2758' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2758/2758 05:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluation metrics: {'eval_loss': 0.228265181183815, 'eval_runtime': 332.1053, 'eval_samples_per_second': 33.218, 'eval_steps_per_second': 8.305, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "logger.info(\"Initializing Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "logger.info(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "logger.info(\"Evaluating model...\")\n",
    "metrics = trainer.evaluate()\n",
    "logger.info(f\"Evaluation metrics: {metrics}\")\n",
    "\n",
    "# Save the fine-tuned model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf3075bc-1882-4681-9bb6-717e0e651738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saving model and tokenizer...\n",
      "INFO:__main__:Training complete.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Saving model and tokenizer...\")\n",
    "model.save_pretrained(\"./fake_news_detector\")\n",
    "tokenizer.save_pretrained(\"./fake_news_detector\")\n",
    "logger.info(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ccf0dd9-e152-44ec-aec2-0b063bd1bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in /opt/anaconda3/lib/python3.12/site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (4.11.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220baa1-ab1e-45b9-ade1-264511be41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic - check this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95730260-1f49-4f5a-8090-38658ee47091",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Universal Smart News Chatbot!\n",
      "Type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  delhi aqi is 800 today\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Prediction: Fake News (Confidence: 0.97)\n",
      "AQI in Delhi is 453.\n",
      "\n",
      "Positive Snippets:\n",
      "- ITI Jahangirpuri, Delhi AQI: ITI Jahangirpuri, Delhi Real-time Air Quality Index (AQI). 372. Hazardous. Updated on Thursday 6:00. temperature: 21°C. current ...\n",
      "- Current New Delhi Air Quality Index (AQI) is 339 Severe level with real-time air pollution PM2.5 (168µg/m³), PM10 (316µg/m³), Temperature (17.7°C) in Delhi.\n",
      "- The AQI in some areas of Delhi stood between 800-1100 - 'hazardous' category - at the time of last update in this report, as per Swiss air ...\n",
      "- AQI values at or below 100 are generally thought of as satisfactory. When AQI values are above 100, air quality is unhealthy: at first for certain sensitive ...\n",
      "\n",
      "Negative Snippets:\n",
      "- Delhi Air Quality Index (AQI) is now Very unhealthy. Get real-time, historical and forecast PM2.5 and weather data. Read the air pollution in Delhi, ...\n",
      "- Current Delhi Air Quality Index (AQI) is 308 Severe level with real-time air pollution PM2.5 (133µg/m³), PM10 (268µg/m³), Temperature (19.3°C) in India.\n",
      "- After yet another 'severe' air day, Delhi's air quality improved slightly to the 'very poor' category on Sunday due to strong winds.\n",
      "- New Delhi air quality index (AQI⁺) forecast ; Today. Very unhealthy 254 AQI⁺ US. Human face indicating AQI level. Weather icon. 78.8° 57.2°. IQAir AirVisual Air ...\n",
      "- Delhi's air quality remained in the \"severe\" category for the fifth day in a row on Sunday, with an air quality index (AQI) of 428 at 7 am.\n",
      "- The air quality, however, continued to worsen and by 6 am on Saturday an average AQI of 422 was reported in the capital. Barring, a few stations ...\n",
      "\n",
      "Validation: Fake News.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  donald trump wins the elections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Prediction: Fake News (Confidence: 0.96)\n",
      "\n",
      "Positive Snippets:\n",
      "- It was clear, but not a landslide by historical standards. Trump won both the Electoral College and the popular vote; in fact, Trump this year ...\n",
      "- View live election results from the 2024 presidential race as Kamala Harris and Donald Trump face off. See the map of votes by state as results are tallied.\n",
      "- Republican President-elect Donald Trump has said his election victory handed him an “unprecedented and powerful” mandate to govern.\n",
      "- There were 93 electoral votes at stake among the seven swing states. Mr. Trump needed at least 51 electoral votes from these states to secure ...\n",
      "- Donald Trump can claim a lot out of his 2024 election win. What Trump cannot claim is a landslide victory, although that's how he will ...\n",
      "- In a decisive victory, Trump wins a series of swing states, while his Republican Party also gains control of the Senate.\n",
      "- Harris' message to supporters: Vice President Kamala Harris urged supporters to accept the 2024 presidential election results and committed to a peaceful ...\n",
      "- Donald Trump was elected the 47th president of the United States on Wednesday, an extraordinary comeback for a former president who refused to accept defeat ...\n",
      "\n",
      "Negative Snippets:\n",
      "\n",
      "Validation: Real News.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  ISRAEL LOST WAE FROM GAZA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Prediction: Real News (Confidence: 0.91)\n",
      "\n",
      "Positive Snippets:\n",
      "- The 7 October Hamas attack overwhelmed Israel and utterly changed its face. The country experienced a tactical defeat after a colossal failure by Israeli ...\n",
      "- After more than a year, Israel and Lebanon have reached a ceasefire agreement that effectively ends the war that Hezbollah began on October 8, ...\n",
      "\n",
      "Negative Snippets:\n",
      "- Failure to Achieve War Aims in Gaza​​ Israel is not achieving its war aims against Hamas. First, it has only obtained a handful of the hostages.\n",
      "- Some argue that Israel has already lost the war in Gaza. Why? First, despite its stated aim of eliminating Hamas, Israel appears unlikely or ...\n",
      "- Hamas already won on Oct. 7 when it embarrassed the Israeli military by overrunning bases, killing Israelis, and taking hostages.\n",
      "- 62 soldiers have been killed in combat, and 15 civilians and two policemen have been killed in missile strikes and attacks inside Israel.\n",
      "- Israel has lost its war on the besieged Gaza Strip and failed to achieve its declared goals of the war, including eliminating Hamas and ...\n",
      "- While Israeli officials claim that Hamas no longer exists as a military force in Gaza, ACLED data show that Hamas still retains some operational capabilities.\n",
      "\n",
      "Validation: Fake News.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import requests\n",
    "from textblob import TextBlob  # For basic sentiment analysis\n",
    "\n",
    "# Initialize tokenizer and model (assuming you have a pre-trained DiOSBERT model for news classification)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('/Users/vineetahuja/Downloads/fake_news_detector_model')  # Update with your DiOSBERT model path\n",
    "\n",
    "# Define your API keys\n",
    "aqi_api_key = '0c55aeba-af32-4ced-989a-d4d5b0b535e9'  # Replace with your AQI API key\n",
    "serp_api_key = '9f1822f370a6c6757264cf88cd1dd65ee80243de84259ab94c413cd093c4c64a'  # Replace with your SerpAPI key\n",
    "weather_api_key = '3463038f0c9c76354f386c470f87824f'  # Replace with your Weather API key\n",
    "sports_api_key = '07bdb0e0aamsh7475b04bc326ccdp10fad6jsnb83610355df6'  # Replace with your Sports API key\n",
    "\n",
    "# Function to fetch AQI data\n",
    "def fetch_aqi_data(city):\n",
    "    url = f'http://api.airvisual.com/v2/city?city={city}&state=Delhi&country=India&key={aqi_api_key}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to fetch weather data\n",
    "def fetch_weather_data(city):\n",
    "    url = f'http://api.weatherapi.com/v1/current.json?key={weather_api_key}&q={city}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to fetch news using SerpAPI\n",
    "def fetch_serp_data(query):\n",
    "    url = f'https://serpapi.com/search?q={query}&api_key={serp_api_key}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to fetch sports data using ESPN Rapid API\n",
    "def fetch_sports_data():\n",
    "    url = f'https://espn-api.com/sportsdata/{sports_api_key}/sports'  # Replace with the correct endpoint if needed\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to predict news validity using DiOSBERT\n",
    "def predict_news(news_text):\n",
    "    inputs = tokenizer(news_text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_class_id = torch.argmax(probabilities, dim=-1).item()\n",
    "    confidence = probabilities[0][predicted_class_id].item()\n",
    "    return predicted_class_id, confidence\n",
    "\n",
    "# Function to analyze sentiment of snippets\n",
    "def analyze_sentiment(snippet):\n",
    "    # Using TextBlob for sentiment analysis (returns polarity)\n",
    "    analysis = TextBlob(snippet)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Function to determine news validity\n",
    "def validate_news(news_text, query):\n",
    "    # Predict the news validity using DiOSBERT\n",
    "    prediction, confidence = predict_news(news_text)\n",
    "    if prediction == 0:\n",
    "        prediction_label = 'Fake News'\n",
    "    else:\n",
    "        prediction_label = 'Real News'\n",
    "\n",
    "    # Fetch relevant news snippets using SerpAPI\n",
    "    serp_data = fetch_serp_data(query)\n",
    "    snippets = serp_data.get('organic_results', [])\n",
    "\n",
    "    # Sentiment analysis of snippets to determine if they support the prediction\n",
    "    positive_snippets = []\n",
    "    negative_snippets = []\n",
    "    for snippet in snippets:\n",
    "        sentiment = analyze_sentiment(snippet['snippet'])\n",
    "        if sentiment > di0:\n",
    "            positive_snippets.append(snippet['snippet'])\n",
    "        else:\n",
    "            negative_snippets.append(snippet['snippet'])\n",
    "\n",
    "    # Handle AQI specific query\n",
    "    aqi_data = None\n",
    "    if 'aqi' in query.lower():\n",
    "        aqi_data = fetch_aqi_data('Delhi')\n",
    "\n",
    "    # Handle Weather specific query\n",
    "    weather_data = None\n",
    "    if 'weather' in query.lower():\n",
    "        weather_data = fetch_weather_data('Delhi')\n",
    "\n",
    "    # Fetch sports data if the query is about sports\n",
    "    sports_data = None\n",
    "    if 'sports' in query.lower():\n",
    "        sports_data = fetch_sports_data()\n",
    "\n",
    "    # Prepare validation message\n",
    "    validation_message = f\"Prediction: {prediction_label} (Confidence: {confidence:.2f})\\n\"\n",
    "\n",
    "    if aqi_data:\n",
    "        aqi_value = aqi_data['data']['current']['pollution']['aqius']\n",
    "        validation_message += f\"AQI in Delhi is {aqi_value}.\\n\"\n",
    "\n",
    "    if weather_data:\n",
    "        temp = weather_data['current']['temp_c']\n",
    "        validation_message += f\"Current temperature in Delhi is {temp}°C.\\n\"\n",
    "\n",
    "    if sports_data:\n",
    "        validation_message += f\"Sports Snippet: {sports_data.get('sports_headline', 'No relevant data available')}\\n\"\n",
    "\n",
    "    # Adding categorized snippets to the validation message\n",
    "    validation_message += \"\\nPositive Snippets:\\n\"\n",
    "    for snippet in positive_snippets:\n",
    "        validation_message += f\"- {snippet}\\n\"\n",
    "\n",
    "    validation_message += \"\\nNegative Snippets:\\n\"\n",
    "    for snippet in negative_snippets:\n",
    "        validation_message += f\"- {snippet}\\n\"\n",
    "\n",
    "    # Final validation message based on the number of positive and negative snippets\n",
    "    if len(positive_snippets) > len(negative_snippets):\n",
    "        validation_message += \"\\nValidation: Real News.\"\n",
    "    else:\n",
    "        validation_message += \"\\nValidation: Fake News.\"\n",
    "\n",
    "    return validation_message\n",
    "\n",
    "# Interactive chat loop\n",
    "def start_chatbot():\n",
    "    print(\"Welcome to the Universal Smart News Chatbot!\")\n",
    "    print(\"Type 'exit' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        response = validate_news(user_input, user_input)\n",
    "        print(\"Bot:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_chatbot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf7c19e-d610-4388-bdb6-fa9b91bee7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to BuzzBot! A smart fake news detector.\n",
      "Ask me about any news, and I'll validate it for you.\n",
      "Type 'exit' to end the chat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import requests\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Initialize tokenizer and model (update with your DiOSBERT model path)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('/Users/vineetahuja/Downloads/fake_news_detector_model')\n",
    "\n",
    "# Define API keys\n",
    "aqi_api_key = '0c55aeba-af32-4ced-989a-d4d5b0b535e9'\n",
    "serp_api_key = '9f1822f370a6c6757264cf88cd1dd65ee80243de84259ab94c413cd093c4c64a'\n",
    "weather_api_key = '3463038f0c9c76354f386c470f87824f'\n",
    "sports_api_key = '07bdb0e0aamsh7475b04bc326ccdp10fad6'\n",
    "\n",
    "# Function to fetch snippets using SerpAPI\n",
    "def fetch_snippets(query):\n",
    "    url = f'https://serpapi.com/search?q={query}&api_key={serp_api_key}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('organic_results', [])\n",
    "    return []\n",
    "\n",
    "# Function for sentiment analysis of snippets\n",
    "def analyze_sentiment(snippet):\n",
    "    analysis = TextBlob(snippet)\n",
    "    return analysis.sentiment.polarity\n",
    "\n",
    "# Function to predict news validity\n",
    "def predict_news(news_text):\n",
    "    inputs = tokenizer(news_text, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_class_id = torch.argmax(probabilities, dim=-1).item()\n",
    "    confidence = probabilities[0][predicted_class_id].item()\n",
    "    return predicted_class_id, confidence\n",
    "\n",
    "# Function to validate news and respond with categorized snippets\n",
    "def validate_news(news_text):\n",
    "    # Predict using the model\n",
    "    prediction, confidence = predict_news(news_text)\n",
    "    prediction_label = 'Real News' if prediction == 1 else 'Fake News'\n",
    "    \n",
    "    # Fetch relevant snippets\n",
    "    snippets = fetch_snippets(news_text)\n",
    "    \n",
    "    positive_snippets = []\n",
    "    negative_snippets = []\n",
    "\n",
    "    for snippet in snippets:\n",
    "        snippet_text = snippet.get('snippet', '')\n",
    "        sentiment = analyze_sentiment(snippet_text)\n",
    "        if sentiment > 0:\n",
    "            positive_snippets.append(snippet_text)\n",
    "        else:\n",
    "            negative_snippets.append(snippet_text)\n",
    "    \n",
    "    # Prepare the response\n",
    "    response = f\"Prediction: {prediction_label} (Confidence: {confidence:.2f})\\n\"\n",
    "    response += \"\\n--- Positive Snippets ---\\n\"\n",
    "    response += \"\\n\".join([f\"- {s}\" for s in positive_snippets]) if positive_snippets else \"No positive snippets found.\\n\"\n",
    "    response += \"\\n\\n--- Negative Snippets ---\\n\"\n",
    "    response += \"\\n\".join([f\"- {s}\" for s in negative_snippets]) if negative_snippets else \"No negative snippets found.\\n\"\n",
    "    \n",
    "    # Final validation\n",
    "    if len(positive_snippets) > len(negative_snippets):\n",
    "        response += \"\\nFinal Validation: Real News.\"\n",
    "    else:\n",
    "        response += \"\\nFinal Validation: Fake News.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# BuzzBot Chat Interface\n",
    "def start_buzzbot():\n",
    "    print(\"Welcome to BuzzBot! A smart fake news detector.\")\n",
    "    print(\"Ask me about any news, and I'll validate it for you.\")\n",
    "    print(\"Type 'exit' to end the chat.\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"BuzzBot: Thank you for using BuzzBot. Stay informed!\")\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                bot_response = validate_news(user_input)\n",
    "                print(f\"BuzzBot:\\n{bot_response}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"BuzzBot: Sorry, I encountered an error: {str(e)}\\n\")\n",
    "\n",
    "# Run the chatbot\n",
    "if __name__ == \"__main__\":\n",
    "    start_buzzbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90935cf-6dfd-429a-bc0d-a78e81967c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
